{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f666ee8",
   "metadata": {},
   "source": [
    "# <font color='#154360'> <b> <center> Embedding Layer </center> </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6256dcf",
   "metadata": {},
   "source": [
    "The embedding layer turns positive integers (indexes) into dense vectors of fixed size.\n",
    "\n",
    "e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>tf_keras.layers.Embedding</b>(\n",
    "    \n",
    "    input_dim,\n",
    "    \n",
    "    output_dim,\n",
    "    \n",
    "    embeddings_initializer=\"uniform\",\n",
    "    \n",
    "    embeddings_regularizer=None,\n",
    "    \n",
    "    activity_regularizer=None,\n",
    "    \n",
    "    embeddings_constraint=None,\n",
    "    \n",
    "    mask_zero=False,\n",
    "    \n",
    "    input_length=None,\n",
    "    \n",
    "    sparse=False,\n",
    "    \n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83597670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6f57d-d2f3-4708-bf26-5ec211740ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485b253a-6253-4c21-9d22-a55c226a9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 5, 4)              80        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80 (320.00 Byte)\n",
      "Trainable params: 80 (320.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Input shape: (2, 5)\n",
      "Output shape: (2, 5, 4)\n",
      "Output[0]:\n",
      " [[ 0.00069342  0.02237742  0.01575348  0.00660519]\n",
      " [-0.00233923 -0.01528187 -0.03285794 -0.03849189]\n",
      " [-0.02080202 -0.02496007 -0.02483844 -0.0109459 ]\n",
      " [-0.03111447  0.04475241 -0.03555129  0.01432693]\n",
      " [-0.02373142  0.03111067 -0.04798113 -0.01596048]]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "First input sentence (word indices): [1 5 2 3 0]\n",
      "\n",
      "Embedding vectors (shape (5, 4)):\n",
      "\n",
      "Word 1 (index 1): [0.00069342 0.02237742 0.01575348 0.00660519]\n",
      "Word 2 (index 5): [-0.00233923 -0.01528187 -0.03285794 -0.03849189]\n",
      "Word 3 (index 2): [-0.02080202 -0.02496007 -0.02483844 -0.0109459 ]\n",
      "Word 4 (index 3): [-0.03111447  0.04475241 -0.03555129  0.01432693]\n",
      "Word 5 (index 0): [-0.02373142  0.03111067 -0.04798113 -0.01596048]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Smaller vocabulary size and embedding dimension for clarity\n",
    "vocab_size = 20       # Just 20 words in the vocab\n",
    "embed_dim = 4         # 4-dimensional embeddings\n",
    "input_length = 5      # Input sentences are 5 words long\n",
    "\n",
    "# Create a simple model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=embed_dim,\n",
    "                           input_length=input_length)\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Sample input: batch of 2 \"sentences\", each with 5 word indices\n",
    "sample_input = np.array([[1, 5, 2, 3, 0],\n",
    "                         [4, 3, 1, 2, 7]])\n",
    "\n",
    "# Run the model and print the output shape and values\n",
    "output = model(sample_input)\n",
    "\n",
    "print(\"Input shape:\", sample_input.shape)         # (2, 5)\n",
    "print(\"Output shape:\", output.shape)              # (2, 5, 4)\n",
    "print(\"Output[0]:\\n\", output[0].numpy())          # Embeddings for first sentence\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Print first input sentence and its embedding\n",
    "print(\"First input sentence (word indices):\", sample_input[0])\n",
    "print(\"\\nEmbedding vectors (shape {}):\\n\".format(output[0].shape))\n",
    "\n",
    "# Loop through each word in the sentence\n",
    "for i, (word_index, embedding_vector) in enumerate(zip(sample_input[0], output[0])):\n",
    "    print(f\"Word {i+1} (index {word_index}): {embedding_vector.numpy()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ead200e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532e731",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[Embedding Layer](https://keras.io/2.15/api/layers/core_layers/embedding/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
